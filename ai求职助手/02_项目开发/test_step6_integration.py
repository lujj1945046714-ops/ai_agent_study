"""
Phase 2 Step 6: å®Œæ•´é›†æˆæµ‹è¯•

æµ‹è¯•åœºæ™¯ï¼ˆä¸éœ€è¦çœŸå® APIï¼Œä½¿ç”¨ mockï¼‰ï¼š
1. å•èŒä½æ·±åº¦åˆ†ææµç¨‹
2. å¤šèŒä½å¯¹æ¯”æµç¨‹
3. è¿½é—®ä¸ä¸Šä¸‹æ–‡ç†è§£
4. å­¦ä¹ è®¡åˆ’åˆ¶å®š
5. ä¼šè¯æŒä¹…åŒ–ä¸æ¢å¤
"""

import json
import sys
from pathlib import Path
from unittest.mock import MagicMock, patch

project_root = Path(__file__).resolve().parent
sys.path.insert(0, str(project_root))

from agent.conversation_memory import ConversationMemory
from agent.suggestion_engine import ProactiveSuggestionEngine
from agent.learning_planner import LearningPlanner
from agent.context_understanding import ContextualUnderstanding

# â”€â”€ æµ‹è¯•æ•°æ® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

MOCK_PROFILE = {
    "name": "æµ‹è¯•ç”¨æˆ·",
    "target_cities": ["ä¸Šæµ·", "åŒ—äº¬"],
    "target_keywords": ["AI Agent", "LLM"],
    "skills": {
        "Python": {"level": 3},
        "FastAPI": {"level": 3},
        "LangChain": {"level": 2},
        "Docker": {"level": 0},
        "Git": {"level": 3},
    }
}

MOCK_JOBS = [
    {
        "job_id": "job-001",
        "title": "AI Agent å·¥ç¨‹å¸ˆ",
        "company": "å…¬å¸A",
        "city": "ä¸Šæµ·",
        "salary": "25-35k",
        "jd_text": "è¦æ±‚ï¼šPythonã€LangChainã€FastAPIã€Docker",
    },
    {
        "job_id": "job-002",
        "title": "LLM åº”ç”¨å·¥ç¨‹å¸ˆ",
        "company": "å…¬å¸B",
        "city": "åŒ—äº¬",
        "salary": "30-40k",
        "jd_text": "è¦æ±‚ï¼šPythonã€LangChainã€Dockerã€K8s",
    },
    {
        "job_id": "job-003",
        "title": "å¤§æ¨¡å‹å·¥ç¨‹å¸ˆ",
        "company": "å…¬å¸C",
        "city": "ä¸Šæµ·",
        "salary": "35-50k",
        "jd_text": "è¦æ±‚ï¼šPythonã€PyTorchã€LangChainã€CUDA",
    },
]

MOCK_ANALYSIS = {
    "required_skills": [
        {"skill": "Python", "level": 3},
        {"skill": "LangChain", "level": 3},
        {"skill": "FastAPI", "level": 2},
    ],
    "tech_stack": [
        {"skill": "Docker", "level": 2},
        {"skill": "Git", "level": 2},
    ],
    "nice_to_have": [
        {"skill": "RAG", "level": 1},
    ],
}

MOCK_MATCH = {
    "score": 71,
    "matched_skills": ["Python", "FastAPI", "Git"],
    "skill_gaps": ["LangChain", "Docker"],
    "skill_gaps_detailed": [
        {"skill": "LangChain", "required_level": 3, "user_level": 2, "category": "required_skills"},
        {"skill": "Docker", "required_level": 2, "user_level": 0, "category": "tech_stack"},
    ],
}

MOCK_REPOS = [
    {"repo": "langchain-ai/langchain", "stars": 90000, "description": "LangChain å®˜æ–¹ä»“åº“"},
    {"repo": "chatchat-space/Langchain-Chatchat", "stars": 30000, "description": "ä¸­æ–‡ RAG åº”ç”¨"},
    {"repo": "langgenius/dify", "stars": 40000, "description": "LLM åº”ç”¨å¼€å‘å¹³å°"},
]

OUTPUT_DIR = project_root / "test_output"
OUTPUT_DIR.mkdir(exist_ok=True)


# â”€â”€ åœºæ™¯ 1: å•èŒä½æ·±åº¦åˆ†æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def test_scenario_single_job():
    """åœºæ™¯1ï¼šå•èŒä½æ·±åº¦åˆ†æ + ä¸»åŠ¨å»ºè®®"""
    print("\n" + "=" * 60)
    print("åœºæ™¯ 1: å•èŒä½æ·±åº¦åˆ†æ")
    print("=" * 60)

    memory = ConversationMemory()
    engine = ProactiveSuggestionEngine()
    planner = LearningPlanner()
    context = ContextualUnderstanding(memory)

    job = MOCK_JOBS[0]
    job_id = job["job_id"]

    # Step 1: åˆ†æèŒä½
    print(f"\n[ç”¨æˆ·] å¸®æˆ‘åˆ†æã€Œ{job['title']}ã€è¿™ä¸ªèŒä½")
    memory.add_job_analysis(job_id, job, MOCK_ANALYSIS)
    print(f"[Agent] å·²åˆ†æèŒä½: {job['title']} @ {job['company']}")

    # Step 2: åŒ¹é…åº¦
    memory.add_match_result(job_id, MOCK_MATCH)
    suggestion = engine.suggest_after_analysis(
        job_id, job["title"],
        MOCK_MATCH["score"],
        MOCK_MATCH["skill_gaps"],
        MOCK_MATCH["matched_skills"]
    )
    print(f"[Agent] åŒ¹é…åº¦: {MOCK_MATCH['score']}åˆ†")
    print(f"[Agent] å»ºè®®çº§åˆ«: {suggestion['level']}")
    print(f"[Agent] {suggestion['message'][:60]}...")
    assert suggestion["level"] == "good", f"æœŸæœ› goodï¼Œå®é™… {suggestion['level']}"

    # Step 3: æ¨èå­¦ä¹ é¡¹ç›®
    print("\n[ç”¨æˆ·] æ¨èå­¦ä¹ é¡¹ç›®")
    memory.add_recommended_projects(job_id, MOCK_REPOS)
    rec_suggestion = engine.suggest_after_recommendation(job["title"], 3, 3)
    print(f"[Agent] å·²æ¨è {len(MOCK_REPOS)} ä¸ªé¡¹ç›®")
    print(f"[Agent] {rec_suggestion['message']}")
    assert len(rec_suggestion["suggestions"]) > 0

    # Step 4: è¿½é—®ã€Œå†æ¨èå‡ ä¸ªã€
    print("\n[ç”¨æˆ·] å†æ¨èå‡ ä¸ª")
    result = context.understand("å†æ¨èå‡ ä¸ª")
    enhanced = context.enhance_with_context(result)
    assert enhanced["intent"] == "recommend_more"
    assert enhanced["references"].get("job_id") == job_id
    assert enhanced["context"].get("already_recommended_count") == 3
    print(f"[ç†è§£] æ„å›¾: {enhanced['intent']}")
    print(f"[ç†è§£] æŒ‡ä»£èŒä½: {enhanced['references'].get('job_title')}")
    print(f"[ç†è§£] å·²æ¨è: {enhanced['context'].get('already_recommended_count')} ä¸ª")

    # Step 5: åˆ¶å®šå­¦ä¹ è®¡åˆ’
    print("\n[ç”¨æˆ·] åˆ¶å®š3ä¸ªæœˆå­¦ä¹ è®¡åˆ’")
    plan = planner.create_plan(MOCK_MATCH["skill_gaps_detailed"], "3months")
    assert plan["feasible"] is True
    assert plan["timeframe"] == "3months"
    print(f"[Agent] å·²åˆ›å»º {plan['timeframe']} å­¦ä¹ è®¡åˆ’")
    print(f"[Agent] å…± {len(plan['phases'])} ä¸ªé˜¶æ®µï¼Œé¢„è®¡ {plan['estimated_weeks']} å‘¨")

    print("\nâœ… åœºæ™¯ 1 é€šè¿‡")
    return True


# â”€â”€ åœºæ™¯ 2: å¤šèŒä½å¯¹æ¯” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def test_scenario_multi_job():
    """åœºæ™¯2ï¼šå¤šèŒä½å¯¹æ¯”"""
    print("\n" + "=" * 60)
    print("åœºæ™¯ 2: å¤šèŒä½å¯¹æ¯”")
    print("=" * 60)

    memory = ConversationMemory()
    engine = ProactiveSuggestionEngine()
    context = ContextualUnderstanding(memory)

    scores = [71, 58, 45]

    # åˆ†æ3ä¸ªèŒä½
    for i, job in enumerate(MOCK_JOBS):
        job_id = job["job_id"]
        memory.add_job_analysis(job_id, job, MOCK_ANALYSIS)
        match = {**MOCK_MATCH, "score": scores[i]}
        memory.add_match_result(job_id, match)
        print(f"[Agent] å·²åˆ†æ: {job['title']} â€” {scores[i]}åˆ†")

    # ç”¨æˆ·è¿½é—®ã€Œå¯¹æ¯”ä¸€ä¸‹ã€
    print("\n[ç”¨æˆ·] å¯¹æ¯”ä¸€ä¸‹è¿™å‡ ä¸ªèŒä½")
    result = context.understand("å¯¹æ¯”ä¸€ä¸‹è¿™å‡ ä¸ªèŒä½")
    enhanced = context.enhance_with_context(result)
    assert enhanced["intent"] == "compare_jobs"
    assert len(enhanced["references"].get("job_ids", [])) == 3
    print(f"[ç†è§£] æ„å›¾: {enhanced['intent']}")
    print(f"[ç†è§£] å¯¹æ¯”èŒä½æ•°: {len(enhanced['references']['job_ids'])}")

    # å¯¹æ¯”å»ºè®®
    suggestion = engine.suggest_job_comparison(3)
    assert len(suggestion["suggestions"]) > 0
    print(f"[Agent] {suggestion['message'][:60]}...")

    # éªŒè¯ä¸Šä¸‹æ–‡ä¸­çš„èŒä½æ•°æ®
    jobs_data = enhanced["context"].get("jobs_data", [])
    assert len(jobs_data) == 3
    # éªŒè¯åˆ†æ•°æ­£ç¡®
    for jd in jobs_data:
        assert jd["score"] in scores
    summary_list = [f"{j['title']}({j['score']}åˆ†)" for j in jobs_data]
    print(f"[Agent] å¯¹æ¯”æ•°æ®: {summary_list}")

    print("\nâœ… åœºæ™¯ 2 é€šè¿‡")
    return True


# â”€â”€ åœºæ™¯ 3: ä¸Šä¸‹æ–‡è¿½é—® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def test_scenario_context_followup():
    """åœºæ™¯3ï¼šå¤šç§è¿½é—®ä¸ä¸Šä¸‹æ–‡ç†è§£"""
    print("\n" + "=" * 60)
    print("åœºæ™¯ 3: è¿½é—®ä¸ä¸Šä¸‹æ–‡ç†è§£")
    print("=" * 60)

    memory = ConversationMemory()
    context = ContextualUnderstanding(memory)

    job = MOCK_JOBS[0]
    memory.add_job_analysis(job["job_id"], job, MOCK_ANALYSIS)
    memory.add_match_result(job["job_id"], MOCK_MATCH)

    test_cases = [
        ("å†æ¨èå‡ ä¸ªé¡¹ç›®",   "recommend_more",  True),
        ("è¿™ä¸ªèŒä½æ€ä¹ˆæ ·",   "query_job",       True),
        ("å¯¹æ¯”ä¸€ä¸‹",         "compare_jobs",    True),
        ("åˆ¶å®šå­¦ä¹ è®¡åˆ’",     "create_plan",     True),
        ("å¸®æˆ‘æœç´¢æ–°èŒä½",   "search_jobs",     False),
        # "åˆ†æè¿™ä¸ªèŒä½" å« "è¿™ä¸ªèŒä½" â†’ åŒ¹é… query_jobï¼ˆæ¨¡å¼ä¼˜å…ˆçº§é«˜äº analyze_jobï¼‰
        ("åˆ†æè¿™ä¸ªèŒä½",     "query_job",       True),
    ]

    all_pass = True
    for user_input, expected_intent, needs_ctx in test_cases:
        result = context.understand(user_input)
        enhanced = context.enhance_with_context(result)
        ok = enhanced["intent"] == expected_intent
        ctx_ok = enhanced["needs_context"] == needs_ctx
        status = "âœ“" if (ok and ctx_ok) else "âœ—"
        print(f"  {status} '{user_input}' â†’ {enhanced['intent']} (éœ€è¦ä¸Šä¸‹æ–‡: {enhanced['needs_context']})")
        if not (ok and ctx_ok):
            all_pass = False

    # æµ‹è¯•è¾“å…¥è¡¥å…¨
    print("\n  è¾“å…¥è¡¥å…¨æµ‹è¯•:")
    completions = [
        ("å†æ¨èå‡ ä¸ª", f"ä¸ºã€Œ{job['title']}ã€å†æ¨èå‡ ä¸ªå­¦ä¹ é¡¹ç›®"),
        ("è¿™ä¸ªèŒä½æ€ä¹ˆæ ·", f"ã€Œ{job['title']}ã€çš„åŒ¹é…åº¦æ€ä¹ˆæ ·ï¼Ÿæœ‰å“ªäº›æŠ€èƒ½ç¼ºå£ï¼Ÿ"),
        ("å¯¹æ¯”ä¸€ä¸‹", "å¯¹æ¯”æ‰€æœ‰å·²åˆ†æçš„èŒä½ï¼Œå¸®æˆ‘é€‰æ‹©æœ€åˆé€‚çš„"),
    ]
    for user_input, expected in completions:
        completed = context.complete_user_input(user_input)
        ok = completed == expected
        status = "âœ“" if ok else "âœ—"
        print(f"  {status} '{user_input}' â†’ '{completed}'")
        if not ok:
            all_pass = False

    assert all_pass, "éƒ¨åˆ†è¿½é—®æµ‹è¯•å¤±è´¥"
    print("\nâœ… åœºæ™¯ 3 é€šè¿‡")
    return True


# â”€â”€ åœºæ™¯ 4: ä¼šè¯æŒä¹…åŒ–ä¸æ¢å¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def test_scenario_session_persistence():
    """åœºæ™¯4ï¼šä¼šè¯æŒä¹…åŒ–ä¸æ¢å¤"""
    print("\n" + "=" * 60)
    print("åœºæ™¯ 4: ä¼šè¯æŒä¹…åŒ–ä¸æ¢å¤")
    print("=" * 60)

    session_file = OUTPUT_DIR / "test_session_step6.json"

    # åˆ›å»ºä¼šè¯å¹¶å¡«å……æ•°æ®
    memory1 = ConversationMemory()
    for job in MOCK_JOBS[:2]:
        memory1.add_job_analysis(job["job_id"], job, MOCK_ANALYSIS)
        memory1.add_match_result(job["job_id"], MOCK_MATCH)
    memory1.add_recommended_projects("job-001", MOCK_REPOS)
    memory1.add_conversation_turn("å¸®æˆ‘åˆ†æèŒä½", "å·²å®Œæˆåˆ†æ")
    memory1.add_conversation_turn("æ¨èå­¦ä¹ é¡¹ç›®", "å·²æ¨è3ä¸ªé¡¹ç›®")

    # ä¿å­˜
    memory1.save(str(session_file))
    print(f"[ä¿å­˜] ä¼šè¯å·²ä¿å­˜: {session_file}")
    print(f"  å·²åˆ†æèŒä½: {len(memory1.analyzed_jobs)}")
    print(f"  å¯¹è¯è½®æ•°: {len(memory1.conversation_history)}")

    # æ¢å¤
    memory2 = ConversationMemory()
    memory2.load(str(session_file))
    print(f"\n[æ¢å¤] ä¼šè¯å·²åŠ è½½")
    print(f"  å·²åˆ†æèŒä½: {len(memory2.analyzed_jobs)}")
    print(f"  å¯¹è¯è½®æ•°: {len(memory2.conversation_history)}")

    # éªŒè¯æ•°æ®å®Œæ•´æ€§
    assert len(memory2.analyzed_jobs) == 2, "èŒä½æ•°ä¸åŒ¹é…"
    assert len(memory2.conversation_history) == 2, "å¯¹è¯è½®æ•°ä¸åŒ¹é…"
    assert memory2.get_last_analyzed_job()["job_id"] == "job-002", "æœ€è¿‘èŒä½ä¸åŒ¹é…"
    assert len(memory2.get_recommended_projects("job-001")) == 3, "æ¨èé¡¹ç›®æ•°ä¸åŒ¹é…"

    # éªŒè¯ä¸Šä¸‹æ–‡æ‘˜è¦
    summary = memory2.get_context_summary()
    assert summary, "ä¸Šä¸‹æ–‡æ‘˜è¦ä¸ºç©º"
    print(f"\n[ä¸Šä¸‹æ–‡æ‘˜è¦]\n{summary[:200]}...")

    # æ¸…ç†
    session_file.unlink()

    print("\nâœ… åœºæ™¯ 4 é€šè¿‡")
    return True


# â”€â”€ åœºæ™¯ 5: å¢å¼ºç‰ˆ Agent å·¥å…·åˆ†å‘ï¼ˆmock LLMï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def test_scenario_agent_dispatch():
    """åœºæ™¯5ï¼šå¢å¼ºç‰ˆ Agent å·¥å…·åˆ†å‘ï¼ˆä¸è°ƒç”¨çœŸå® LLMï¼‰"""
    print("\n" + "=" * 60)
    print("åœºæ™¯ 5: Agent å·¥å…·åˆ†å‘ï¼ˆmockï¼‰")
    print("=" * 60)

    from agent.react_agent_enhanced import JobSearchAgent

    agent = JobSearchAgent(
        user_profile=MOCK_PROFILE,
        api_key="mock-key",
        base_url="https://api.deepseek.com",
        model="deepseek-chat",
        output_dir=OUTPUT_DIR,
        name="step6_test",
        enable_phase2=True,
    )
    agent.preload_jobs(MOCK_JOBS)

    # mock tool_analyze_job
    with patch("agent.react_agent_enhanced.tool_analyze_job", return_value=MOCK_ANALYSIS), \
         patch("agent.react_agent_enhanced.tool_match_job", return_value=MOCK_MATCH), \
         patch("agent.react_agent_enhanced.tool_recommend_learning", return_value={"repos": MOCK_REPOS}):

        # æµ‹è¯• analyze_job
        result = agent._dispatch("analyze_job", {"job_id": "job-001"})
        assert "required_skills" in result, "analyze_job è¿”å›æ ¼å¼é”™è¯¯"
        assert agent._results["job-001"]["analysis"] == MOCK_ANALYSIS
        assert agent.conversation_memory.get_last_analyzed_job()["job_id"] == "job-001"
        print("  âœ“ analyze_job â†’ è®°å¿†å·²æ›´æ–°")

        # æµ‹è¯• match_job
        result = agent._dispatch("match_job", {"job_id": "job-001"})
        assert result["score"] == 71
        assert "proactive_suggestion" in result
        assert agent.conversation_memory.get_match_result("job-001") is not None
        print("  âœ“ match_job â†’ ä¸»åŠ¨å»ºè®®å·²ç”Ÿæˆ")

        # æµ‹è¯• recommend_learning
        result = agent._dispatch("recommend_learning", {"job_id": "job-001", "skill_gaps": ["LangChain"]})
        assert "repos" in result
        assert "proactive_suggestion" in result
        print("  âœ“ recommend_learning â†’ æ¨èå»ºè®®å·²ç”Ÿæˆ")

        # æµ‹è¯• create_learning_plan
        result = agent._dispatch("create_learning_plan", {"job_id": "job-001", "timeframe": "3months"})
        assert result.get("success") is True
        assert "plan" in result
        print("  âœ“ create_learning_plan â†’ å­¦ä¹ è®¡åˆ’å·²ç”Ÿæˆ")

        # æµ‹è¯• compare_jobsï¼ˆéœ€è¦2ä¸ªèŒä½çš„ç»“æœï¼‰
        agent._results["job-002"] = {"analysis": MOCK_ANALYSIS, "match": {**MOCK_MATCH, "score": 58}}
        result = agent._dispatch("compare_jobs", {})
        assert result.get("success") is True
        assert len(result["comparison"]) == 2
        # éªŒè¯æŒ‰åˆ†æ•°é™åºæ’åˆ—
        assert result["comparison"][0]["score"] >= result["comparison"][1]["score"]
        print("  âœ“ compare_jobs â†’ å¯¹æ¯”ç»“æœå·²æ’åº")

    print("\nâœ… åœºæ™¯ 5 é€šè¿‡")
    return True


# â”€â”€ ä¸»æµ‹è¯•å…¥å£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run_all():
    print("\n" + "=" * 60)
    print("Phase 2 Step 6: å®Œæ•´é›†æˆæµ‹è¯•")
    print("=" * 60)

    scenarios = [
        ("å•èŒä½æ·±åº¦åˆ†æ",     test_scenario_single_job),
        ("å¤šèŒä½å¯¹æ¯”",         test_scenario_multi_job),
        ("è¿½é—®ä¸ä¸Šä¸‹æ–‡ç†è§£",   test_scenario_context_followup),
        ("ä¼šè¯æŒä¹…åŒ–ä¸æ¢å¤",   test_scenario_session_persistence),
        ("Agent å·¥å…·åˆ†å‘",     test_scenario_agent_dispatch),
    ]

    results = []
    for name, fn in scenarios:
        try:
            ok = fn()
            results.append((name, ok))
        except Exception as e:
            import traceback
            print(f"\nâŒ {name} å¤±è´¥: {e}")
            traceback.print_exc()
            results.append((name, False))

    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    passed = sum(1 for _, ok in results if ok)
    for name, ok in results:
        print(f"  {'âœ…' if ok else 'âŒ'} {name}")
    print(f"\næ€»è®¡: {passed}/{len(results)} é€šè¿‡")

    if passed == len(results):
        print("\nğŸ‰ Step 6 å…¨éƒ¨é€šè¿‡ï¼Phase 2 å®Œæˆï¼")
    else:
        print(f"\nâš ï¸ {len(results) - passed} ä¸ªåœºæ™¯å¤±è´¥")

    return passed == len(results)


if __name__ == "__main__":
    success = run_all()
    exit(0 if success else 1)
